import torch
generator = torch.Generator("cuda").manual_seed(0)
image = pipeline(prompt, generator=generator).images[0]



when using a pipeline, always use torch_dtype = torch.float16 to save time when loading the pipeline



The Stable Diffusion model uses the PNDMScheduler by default which usually requires ~50 inference steps,
 but more performant schedulers like DPMSolverMultistepScheduler, require only ~20 or 25 inference steps. 
 Use the ConfigMixin.from_config() method to load a new scheduler:

from diffusers import DPMSolverMultistepScheduler
pipeline.scheduler = DPMSolverMultistepScheduler.from_config(pipeline.scheduler.config)


from diffusers.utils import make_image_grid 

images = pipeline(**get_inputs(batch_size=4)).images
make_image_grid(images, 2, 2)
pipeline.enable_attention_slicing()

def get_inputs(batch_size=1):
    generator = [torch.Generator("cuda").manual_seed(i) for i in range(batch_size)]
    prompts = batch_size * [prompt]
    num_inference_steps = 20

    return {"prompt": prompts, "generator": generator, "num_inference_steps": num_inference_steps}

Another option is to reduce the number of inference steps. 
Choosing a more efficient scheduler could help decrease the number of steps without sacrificing output quality. 
You can find which schedulers are compatible with the current model in the DiffusionPipeline 
by calling the compatibles method:




For some workflows or if you’re loading many pipelines, it is more memory-efficient to reuse the same components 
from a checkpoint instead of reloading them which would unnecessarily consume additional memory. For example, 
if you’re using a checkpoint for text-to-image and you want to use it again for image-to-image, use the from_pipe() 
method. This method creates a new pipeline from the components of a previously loaded pipeline at no additional memory cost.

The from_pipe() method detects the original pipeline class and maps 
it to the new pipeline class corresponding to the task you want to do. For example, 
if you load a "stable-diffusion" class pipeline for text-to-image:

pipeline_img2img = AutoPipelineForImage2Image.from_pipe(pipeline_text2img)



modified safetychecker.py in stable diffusion pipeline folder, make sure to change back later



You can find additional datasets from the HugGan Community Event or you can use your own dataset by 
creating a local ImageFolder. Set config.dataset_name to the repository id of the dataset if it is 
from the HugGan Community Event, or imagefolder if you’re using your own images.